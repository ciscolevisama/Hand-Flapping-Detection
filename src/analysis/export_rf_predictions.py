import os
import pandas as pd
import joblib
from sklearn.metrics import classification_report

# === è·¯å¾„é…ç½® ===
model_path = "runs/clean/model_rf.pkl"
feature_file = "data/window_features/all_window_features.csv"
label_csv = "data/labels/weak_labels.csv"

# === åŠ è½½æ¨¡å‹å’Œæ•°æ® ===
print(f"âœ… Using model: {model_path}")
print(f"âœ… Using features: {feature_file}")
print(f"âœ… Using labels: {label_csv}")

rf = joblib.load(model_path)
df = pd.read_csv(feature_file)

# ---- æ˜ç¡®é€‰å–ç”¨äºè®­ç»ƒçš„ç‰¹å¾åˆ— ----
feature_cols = ["A_left", "A_right", "freq", "delta_A", "H_left", "H_right", "valid_ratio"]
X = df[feature_cols]
print(f"ğŸ§© Using {len(feature_cols)} feature columns: {feature_cols}")

y = pd.read_csv(label_csv)["label"]

# === æ£€æŸ¥é•¿åº¦ä¸€è‡´æ€§ ===
if len(X) != len(y):
    print(f"âš ï¸ Warning: X ({len(X)}) and y ({len(y)}) length mismatch. Truncating to min length.")
    n = min(len(X), len(y))
    X, y = X.iloc[:n], y.iloc[:n]

# === é¢„æµ‹ä¸è¯„ä¼° ===
y_pred = rf.predict(X)

print("\nClassification Report:")
print(classification_report(y, y_pred, digits=3))

# === å¯¼å‡ºé¢„æµ‹ç»“æœ ===
df_out = pd.DataFrame({"true_label": y, "pred_label": y_pred})
os.makedirs("runs_ml", exist_ok=True)
out_path = "runs_ml/preds_rf.csv"
df_out.to_csv(out_path, index=False)

print(f"\nâœ… Exported prediction results: {out_path}")
