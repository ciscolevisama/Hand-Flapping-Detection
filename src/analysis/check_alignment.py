# -*- coding: utf-8 -*-
"""
Quick diagnostic: check alignment between raw video, extracted features, and weak labels.
Usage:
    python src/analysis/check_alignment.py --video Flapping_her_arms_KPuLA5LlVjg.mp4
"""

import os, argparse, json
import cv2, numpy as np, pandas as pd
import matplotlib.pyplot as plt
from pathlib import Path

# === è‡ªåŠ¨å®šä½é¡¹ç›®æ ¹ç›®å½• ===
ROOT = Path(__file__).resolve().parents[2]


def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--video", required=True, help="Video file name (e.g. Flapping_her_arms_KPuLA5LlVjg.mp4)")
    ap.add_argument("--label_csv", default=str(ROOT / "data" / "labels" / "weak_labels.csv"))
    ap.add_argument("--proc_dir", default=str(ROOT / "data" / "processed_angles"))
    args = ap.parse_args()

    video_name = args.video
    stem = Path(video_name).stem

    # === 1ï¸âƒ£ è§†é¢‘å¸§æ•°ä¸ŽFPS ===
    video_path = ROOT / "data" / "raw_videos" / video_name
    if not video_path.exists():
        raise FileNotFoundError(f"âŒ Video not found: {video_path}")

    cap = cv2.VideoCapture(str(video_path))
    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    fps = cap.get(cv2.CAP_PROP_FPS)
    duration = frame_count / fps if fps > 0 else 0
    cap.release()

    print(f"\nðŸŽžï¸  Video: {video_name}")
    print(f"   - Frames: {frame_count}")
    print(f"   - FPS: {fps:.2f}")
    print(f"   - Duration: {duration:.2f} s")

    # === 2ï¸âƒ£ å¯¹åº”ç‰¹å¾å¸§æ•° ===
    feat_path = Path(args.proc_dir) / f"{stem}.npy"
    if not feat_path.exists():
        print(f"âš ï¸  Feature file not found: {feat_path}")
        feat_count = 0
    else:
        feat = np.load(feat_path)
        feat_count = feat.shape[0]
        print(f"   - Extracted feature frames: {feat_count}")

    # === å¸§æ•°å·®å¼‚åˆ†æž ===
    if frame_count > 0 and feat_count > 0:
        diff = frame_count - feat_count
        ratio = feat_count / frame_count
        print(f"   - Feature/Video ratio: {ratio * 100:.2f}%")
        if ratio < 0.9:
            print("âš ï¸  Large mismatch detected (possible NaN frame drops during extraction).")

    # === 3ï¸âƒ£ æ ‡ç­¾åŒºé—´æ£€æŸ¥ ===
    df = pd.read_csv(args.label_csv)
    if "video" not in df.columns:
        raise ValueError("âŒ weak_labels.csv missing 'video' column.")
    df_v = df[df["video"].str.contains(stem, na=False)]
    if len(df_v) == 0:
        print(f"âš ï¸  No labels found for {stem} in weak_labels.csv")
    else:
        print("\nðŸ§¾ Weak labels for this video:")
        print(df_v[["start_frame", "end_frame", "label", "confidence"]])
        label_starts = df_v["start_frame"].min()
        label_ends = df_v["end_frame"].max()
        print(
            f"   - Labelled range: {label_starts}â€“{label_ends} (duration â‰ˆ {(label_ends - label_starts) / fps:.2f} s)")

        # å¦‚æžœæ ‡ç­¾è¶…è¿‡ç‰¹å¾å¸§èŒƒå›´ï¼Œè¯´æ˜Žé”™ä½
        if label_ends > feat_count:
            print(f"âš ï¸  Label end ({label_ends}) > feature length ({feat_count}) â†’ misalignment likely.")

    # === 4ï¸âƒ£ ç®€å•æ—¶é—´è½´å¯è§†åŒ– ===
    if feat_count > 0:
        plt.figure(figsize=(8, 1))
        plt.hlines(1, 0, frame_count, color="gray", linewidth=6, label="Video frames")
        plt.hlines(1.1, 0, feat_count, color="orange", linewidth=6, label="Extracted features")
        if len(df_v) > 0:
            for _, row in df_v.iterrows():
                plt.hlines(1.2, row["start_frame"], row["end_frame"], color="green", linewidth=6)
        plt.legend()
        plt.xlabel("Frame index")
        plt.yticks([])
        plt.title(f"Alignment check: {stem}")
        plt.tight_layout()
        plt.show()

    print("\nâœ… Check complete.")
    print("   If feature length << video frames â†’ Mediapipe dropped many frames.")
    print("   If label end > feature length â†’ labels misaligned.")
    print("   If labels appear shifted â†’ use offset=32â€“64 in visualize_prediction.")


if __name__ == "__main__":
    main()
